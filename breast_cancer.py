# -*- coding: utf-8 -*-
"""Breast_Cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hfvsle24UOzAGtDj-rJ39letcBfTVics
"""



from sklearn.datasets import load_breast_cancer
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.svm import SVC
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler,MinMaxScaler
import time

df = load_breast_cancer() #Load breast cancer data from sklearn
X = df.data                 # features
y = df.target               # target

X.shape                     # (569, 30)

y.shape                     # (569,)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)      # split data to train and test

model=LogisticRegression(max_iter=90, verbose=1)                # Use logistic regression model because data is discrete 
                                                                # maximum number of iterations for the solver to converge is 90
model.fit(X_train, y_train)

target_predict = model.predict(X_test)
model_score= model.score(X_test, y_test)
model_score                # 0.9707602339181286


print(metrics.classification_report(y_test, target_predict))

                            #     precision    recall  f1-score   support
                            
                            #          0       0.98      0.94      0.96        63
                            #          1       0.96      0.99      0.98       108
                            
                            #    accuracy                           0.97       171
                            #   macro avg       0.97      0.96      0.97       171
                            #weighted avg       0.97      0.97      0.97       171
                            

start_rbf=time.time()

svm_rbf = SVC(kernel="rbf")   # try another model Support Vector Classifier (SVC) with the Radial Basis Function (RBF) kernel

svm_rbf.fit(X_train, y_train)

target_predict_rbf = svm_rbf.predict(X_test)
model_score_rbf= svm_rbf.score(X_test, y_test)
model_score_rbf               # 0.935672514619883

r_rbf=metrics.classification_report(y_test, target_predict_rbf,output_dict=True)
print(metrics.classification_report(y_test, target_predict_rbf ))
                                #               precision    recall  f1-score   support
                                
                                 #          0       1.00      0.83      0.90        63
                                 #          1       0.91      1.00      0.95       108
                                
                                 #   accuracy                           0.94       171
                                 #  macro avg       0.95      0.91      0.93       171
                                # weighted avg       0.94      0.94      0.93       171


end_rbf= time.time()

Time_taken_rbf=end_rbf - start_rbf
Time_taken_rbf

start_poly= time.time()

svm_poly = SVC(kernel="poly")        # try another model Support Vector Classifier (SVC) with the polynomial kernel ('poly')

svm_poly.fit(X_train, y_train)

target_predict_poly = svm_poly.predict(X_test)
model_score_poly= svm_poly.score(X_test, y_test)
model_score_poly                     # 0.9415204678362573


r_poly=metrics.classification_report(y_test, target_predict_poly,output_dict=True)

print(metrics.classification_report(y_test, target_predict_poly))

end_poly= time.time()

Time_taken_poly=end_poly - start_poly
Time_taken_poly

start_linear= time.time()

svm_linear = SVC(kernel="linear")

svm_linear.fit(X_train, y_train)

target_predict_linear = svm_linear.predict(X_test)
model_score_linear= svm_linear.score(X_test, y_test)
model_score_linear

r_linear=metrics.classification_report(y_test, target_predict_linear,output_dict=True)
print(metrics.classification_report(y_test, target_predict_linear))

end_linear= time.time()

Time_taken_linear=end_linear - start_linear
Time_taken_linear

start_sigmoid= time.time()

svm_sigmoid = SVC(kernel="sigmoid")

svm_sigmoid.fit(X_train, y_train)

target_predict_sigmoid = svm_sigmoid.predict(X_test)
model_score_sigmoid= svm_sigmoid.score(X_test, y_test)
model_score_sigmoid

r_sigmoid=metrics.classification_report(y_test, target_predict_sigmoid,output_dict=True)

print(metrics.classification_report(y_test, target_predict_sigmoid))

end_sigmoid= time.time()

Time_taken_sigmoid=end_sigmoid - start_sigmoid
Time_taken_sigmoid

Result = {'Kernal': ['rbf', 'poly', 'linear', 'sigmoid'],
        'Accuracy': [model_score_rbf, model_score_poly, model_score_linear, model_score_sigmoid],
          'Precision':[r_rbf['1']['precision'],r_poly['1']['precision'],r_linear['1']['precision'],r_sigmoid['1']['precision']],
          'Recall':[r_rbf['1']['recall'],r_poly['1']['recall'],r_linear['1']['recall'],r_sigmoid['1']['recall']],
          'F1_score':[r_rbf['1']['f1-score'],r_poly['1']['f1-score'],r_linear['1']['f1-score'],r_sigmoid['1']['f1-score']],
          'Time_taken':[Time_taken_rbf,Time_taken_poly,Time_taken_linear,Time_taken_sigmoid],}

# Create DataFrame
df_result = pd.DataFrame(Result)
df_result


#	Kernal	Accuracy	Precision	Recall	F1_score	Time_taken
# 0	 rbf	0.935673	0.907563	1.000000	0.951542	0.115654
# 1	 poly	0.941520	0.922414	0.990741	0.955357	0.107156
# 2	linear	0.964912	0.963636	0.981481	0.972477	1.398122
# 3	sigmoid	0.467836	0.566929	0.666667	0.612766	0.103167
# 4	logistic0.970760	0.963964	0.990741	0.977169	0.145646
